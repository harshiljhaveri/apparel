{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4tcpeG9-MA",
        "outputId": "c372fc56-4a50-49fc-a755-fa7b8bdea4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cd '/content/gdrive/My Drive/train'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry6JmA-5uTqE"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        " CV_IO_utils.py\n",
        "\n",
        "\"\"\"\n",
        "import os\n",
        "import skimage.io\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Read image\n",
        "def read_img(filePath):\n",
        "    return skimage.io.imread(filePath, as_gray=False)\n",
        "\n",
        "# Read images with common extensions from a directory\n",
        "def read_imgs_dir(dirPath, extensions, parallel=True):    \n",
        "    # args = []\n",
        "    # for i in os.listdir(dirPath):\n",
        "    #     for filename in os.listdir(os.path.join(dirPath, i)):\n",
        "    #         arg = [os.path.join(dirPath, i, filename)]\n",
        "    #     args.extend(arg)\n",
        "    args = [os.path.join(dirPath, filename)\n",
        "            for filename in os.listdir(dirPath)\n",
        "            if any(filename.lower().endswith(ext) for ext in extensions)]\n",
        "    if parallel:\n",
        "        pool = Pool()\n",
        "        imgs = pool.map(read_img, args)\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "    else:\n",
        "        imgs = [read_img(arg) for arg in args]\n",
        "    return imgs\n",
        "\n",
        "# Save image to file\n",
        "def save_img(filePath, img):\n",
        "    skimage.io.imsave(filePath, img)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgtnQ2bV4IUA"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Apply transformations to multiple images\n",
        "def apply_transformer(imgs, transformer, parallel=True):\n",
        "    if parallel:\n",
        "        pool = Pool()\n",
        "        imgs_transform = pool.map(transformer, [img for img in imgs])\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "    else:\n",
        "        imgs_transform = [transformer(img) for img in imgs]\n",
        "    return imgs_transform\n",
        "\n",
        "# Normalize image data [0, 255] -> [0.0, 1.0]\n",
        "def normalize_img(img):\n",
        "    return img / 255.\n",
        "\n",
        "# Resize image\n",
        "def resize_img(img, shape_resized):\n",
        "    img_resized = resize(img, shape_resized,\n",
        "                         anti_aliasing=True,\n",
        "                         preserve_range=True)\n",
        "    assert img_resized.shape == shape_resized\n",
        "    return img_resized\n",
        "\n",
        "# Flatten image\n",
        "def flatten_img(img):\n",
        "    return img.flatten(\"C\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9DW6ZEu4Ji5"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        " utils.py (author: Anson Wong / git: ankonzoid)\n",
        "\n",
        "\"\"\"\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Get split indices\n",
        "def split(fracs, N, seed):\n",
        "    fracs = [round(frac, 2) for frac in fracs]\n",
        "    if sum(fracs) != 1.00:\n",
        "        raise Exception(\"fracs do not sum to one!\")\n",
        "\n",
        "    # Shuffle ordered indices\n",
        "    indices = list(range(N))\n",
        "    random.Random(seed).shuffle(indices)\n",
        "    indices = np.array(indices, dtype=int)\n",
        "\n",
        "    # Get numbers per group\n",
        "    n_fracs = []\n",
        "    for i in range(len(fracs) - 1):\n",
        "        n_fracs.append(int(max(fracs[i] * N, 0)))\n",
        "    n_fracs.append(int(max(N - sum(n_fracs), 0)))\n",
        "\n",
        "    if sum(n_fracs) != N:\n",
        "        raise Exception(\"n_fracs do not sum to N!\")\n",
        "\n",
        "    # Sample indices\n",
        "    n_selected = 0\n",
        "    indices_fracs = []\n",
        "    for n_frac in n_fracs:\n",
        "        indices_frac = indices[n_selected:n_selected + n_frac]\n",
        "        indices_fracs.append(indices_frac)\n",
        "        n_selected += n_frac\n",
        "\n",
        "    # Check no intersections\n",
        "    for a, indices_frac_A in enumerate(indices_fracs):\n",
        "        for b, indices_frac_B in enumerate(indices_fracs):\n",
        "            if a == b:\n",
        "                continue\n",
        "            if is_intersect(indices_frac_A, indices_frac_B):\n",
        "                raise Exception(\"there are intersections!\")\n",
        "\n",
        "    return indices_fracs\n",
        "\n",
        "# Is there intersection?\n",
        "def is_intersect(arr1, arr2):\n",
        "    n_intersect = len(np.intersect1d(arr1, arr2))\n",
        "    if n_intersect == 0: return False\n",
        "    else: return True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnLwFK9k4EL6"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        " CV_plot_utils.py  (author: Anson Wong / git: ankonzoid)\n",
        "\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import offsetbox\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from sklearn import manifold\n",
        "\n",
        "# Plot image\n",
        "def plot_img(img, range=[0, 255]):\n",
        "    plt.imshow(img, vmin=range[0], vmax=range[1])\n",
        "    plt.xlabel(\"xpixels\")\n",
        "    plt.ylabel(\"ypixels\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Plots images in 2 rows: top row is query, bottom row is answer\n",
        "def plot_query_retrieval(img_query, imgs_retrieval, outFile):\n",
        "    n_retrieval = len(imgs_retrieval)\n",
        "    fig = plt.figure(figsize=(2*n_retrieval, 4))\n",
        "    fig.suptitle(\"Image Retrieval (k={})\".format(n_retrieval), fontsize=25)\n",
        "\n",
        "    # Plot query image\n",
        "    ax = plt.subplot(2, n_retrieval, 0 + 1)\n",
        "    plt.imshow(img_query)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    for axis in ['top', 'bottom', 'left', 'right']:\n",
        "        ax.spines[axis].set_linewidth(4)  # increase border thickness\n",
        "        ax.spines[axis].set_color('black')  # set to black\n",
        "    ax.set_title(\"query\",  fontsize=14)  # set subplot title\n",
        "\n",
        "    # Plot retrieval images\n",
        "    for i, img in enumerate(imgs_retrieval):\n",
        "        ax = plt.subplot(2, n_retrieval, n_retrieval + i + 1)\n",
        "        plt.imshow(img)\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        for axis in ['top', 'bottom', 'left', 'right']:\n",
        "            ax.spines[axis].set_linewidth(1)  # set border thickness\n",
        "            ax.spines[axis].set_color('black')  # set to black\n",
        "        ax.set_title(\"Rank #%d\" % (i+1), fontsize=14)  # set subplot title\n",
        "\n",
        "    if outFile is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(outFile, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Plot t-SNE of images\n",
        "def plot_tsne(X, imgs, outFile):\n",
        "\n",
        "    def imscatter(x, y, images, ax=None, zoom=1.0):\n",
        "        if ax is None:\n",
        "            ax = plt.gca()\n",
        "        x, y = np.atleast_1d(x, y)\n",
        "        artists = []\n",
        "        for x0, y0, img0 in zip(x, y, images):\n",
        "            im = OffsetImage(img0, zoom=zoom)\n",
        "            ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=True)\n",
        "            artists.append(ax.add_artist(ab))\n",
        "        ax.update_datalim(np.column_stack([x, y]))\n",
        "        ax.autoscale()\n",
        "        return artists\n",
        "\n",
        "    def plot_embedding(X, imgs, title=None):\n",
        "        x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "        X = (X - x_min) / (x_max - x_min)\n",
        "\n",
        "        plt.figure()\n",
        "        ax = plt.subplot(111)\n",
        "        for i in range(X.shape[0]):\n",
        "            plt.text(X[i, 0], X[i, 1], \".\", fontdict={'weight': 'bold', 'size': 9})\n",
        "        if hasattr(offsetbox, 'AnnotationBbox'):\n",
        "            imscatter(X[:,0], X[:,1], imgs, zoom=0.3, ax=ax)\n",
        "\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "        if title is not None:\n",
        "            plt.title(title, fontsize=18)\n",
        "\n",
        "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
        "    X_tsne = tsne.fit_transform(X)\n",
        "    plot_embedding(X_tsne, imgs, \"t-SNE embeddings\")\n",
        "    if outFile is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(outFile, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Plot image reconstructions\n",
        "def plot_reconstructions(imgs, imgs_reconstruct, outFile,\n",
        "                         range_imgs=[0, 255],\n",
        "                         range_imgs_reconstruct=[0, 1]):\n",
        "    # Create plot to save\n",
        "    assert len(imgs) == len(imgs_reconstruct)\n",
        "    fig = plt.figure(figsize=(20, 4))\n",
        "    fig.suptitle(\"Image Reconstructions\", fontsize=35)\n",
        "    n = min(len(imgs), 10)\n",
        "    for i in range(n):\n",
        "\n",
        "        # Plot original image\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(imgs[i],\n",
        "                   vmin=range_imgs[0],\n",
        "                   vmax=range_imgs[1])\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # Plot reconstructed image\n",
        "        ax = plt.subplot(2, n, n + i + 1)\n",
        "        plt.imshow(imgs_reconstruct[i],\n",
        "                   vmin=range_imgs_reconstruct[0],\n",
        "                   vmax=range_imgs_reconstruct[1])\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    if outFile is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(outFile, bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPGbFq6D33Ek"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        " autoencoder.py  (author: Anson Wong / git: ankonzoid)\n",
        "\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class AutoEncoder():\n",
        "\n",
        "    def __init__(self, modelName, info):\n",
        "        self.modelName = modelName\n",
        "        self.info = info\n",
        "        self.autoencoder = None\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "\n",
        "    # Train\n",
        "    def fit(self, X, n_epochs=50, batch_size=256):\n",
        "        indices_fracs = split(fracs=[0.9, 0.1], N=len(X), seed=0)\n",
        "        X_train, X_valid = X[indices_fracs[0]], X[indices_fracs[1]]\n",
        "        self.autoencoder.fit(X_train, X_train,\n",
        "                             epochs = n_epochs,\n",
        "                             batch_size = batch_size,\n",
        "                             shuffle = True,\n",
        "                             validation_data = (X_valid, X_valid))\n",
        "\n",
        "    # Inference\n",
        "    def predict(self, X):\n",
        "        return self.encoder.predict(X)\n",
        "\n",
        "    # Set neural network architecture\n",
        "    def set_arch(self):\n",
        "\n",
        "        shape_img = self.info[\"shape_img\"]\n",
        "        shape_img_flattened = (np.prod(list(shape_img)),)\n",
        "\n",
        "        # Set encoder and decoder graphs\n",
        "        if self.modelName == \"simpleAE\":\n",
        "            encode_dim = 128\n",
        "\n",
        "            input = tf.keras.Input(shape=shape_img_flattened)\n",
        "            encoded = tf.keras.layers.Dense(encode_dim, activation='relu')(input)\n",
        "\n",
        "            decoded = tf.keras.layers.Dense(shape_img_flattened[0], activation='sigmoid')(encoded)\n",
        "\n",
        "        elif self.modelName == \"convAE\":\n",
        "            n_hidden_1, n_hidden_2, n_hidden_3 = 16, 8, 8\n",
        "            convkernel = (3, 3)  # convolution kernel\n",
        "            poolkernel = (2, 2)  # pooling kernel\n",
        "\n",
        "            input = tf.keras.layers.Input(shape=shape_img)\n",
        "            x = tf.keras.layers.Conv2D(n_hidden_1, convkernel, activation='relu', padding='same')(input)\n",
        "            x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)\n",
        "            x = tf.keras.layers.Conv2D(n_hidden_2, convkernel, activation='relu', padding='same')(x)\n",
        "            x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)\n",
        "            x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(x)\n",
        "            encoded = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)\n",
        "\n",
        "            x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(encoded)\n",
        "            x = tf.keras.layers.UpSampling2D(poolkernel)(x)\n",
        "            x = tf.keras.layers.Conv2D(n_hidden_2, convkernel, activation='relu', padding='same')(x)\n",
        "            x = tf.keras.layers.UpSampling2D(poolkernel)(x)\n",
        "            x = tf.keras.layers.Conv2D(n_hidden_1, convkernel, activation='relu')(x)\n",
        "            x = tf.keras.layers.UpSampling2D(poolkernel)(x)\n",
        "            decoded = tf.keras.layers.Conv2D(shape_img[2], convkernel, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"Invalid model name given!\")\n",
        "\n",
        "        # Create autoencoder model\n",
        "        autoencoder = tf.keras.Model(input, decoded)\n",
        "        input_autoencoder_shape = autoencoder.layers[0].input_shape[1:]\n",
        "        output_autoencoder_shape = autoencoder.layers[-1].output_shape[1:]\n",
        "\n",
        "        # Create encoder model\n",
        "        encoder = tf.keras.Model(input, encoded)  # set encoder\n",
        "        input_encoder_shape = encoder.layers[0].input_shape[1:]\n",
        "        output_encoder_shape = encoder.layers[-1].output_shape[1:]\n",
        "\n",
        "        # Create decoder model\n",
        "        decoded_input = tf.keras.Input(shape=output_encoder_shape)\n",
        "        if self.modelName == 'simpleAE':\n",
        "            decoded_output = autoencoder.layers[-1](decoded_input)  # single layer\n",
        "        elif self.modelName == 'convAE':\n",
        "            decoded_output = autoencoder.layers[-7](decoded_input)  # Conv2D\n",
        "            decoded_output = autoencoder.layers[-6](decoded_output)  # UpSampling2D\n",
        "            decoded_output = autoencoder.layers[-5](decoded_output)  # Conv2D\n",
        "            decoded_output = autoencoder.layers[-4](decoded_output)  # UpSampling2D\n",
        "            decoded_output = autoencoder.layers[-3](decoded_output)  # Conv2D\n",
        "            decoded_output = autoencoder.layers[-2](decoded_output)  # UpSampling2D\n",
        "            decoded_output = autoencoder.layers[-1](decoded_output)  # Conv2D\n",
        "        else:\n",
        "            raise Exception(\"Invalid model name given!\")\n",
        "        decoder = tf.keras.Model(decoded_input, decoded_output)\n",
        "        decoder_input_shape = decoder.layers[0].input_shape[1:]\n",
        "        decoder_output_shape = decoder.layers[-1].output_shape[1:]\n",
        "\n",
        "        # Generate summaries\n",
        "        print(\"\\nautoencoder.summary():\")\n",
        "        print(autoencoder.summary())\n",
        "        print(\"\\nencoder.summary():\")\n",
        "        print(encoder.summary())\n",
        "        print(\"\\ndecoder.summary():\")\n",
        "        print(decoder.summary())\n",
        "\n",
        "        # Assign models\n",
        "        self.autoencoder = autoencoder\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    # Compile\n",
        "    def compile(self, loss=\"binary_crossentropy\", optimizer=\"adam\"):\n",
        "        self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    # Load model architecture and weights\n",
        "    def load_models(self, loss=\"binary_crossentropy\", optimizer=\"adam\"):\n",
        "        print(\"Loading models...\")\n",
        "        self.autoencoder = tf.keras.models.load_model(self.info[\"autoencoderFile\"])\n",
        "        self.encoder = tf.keras.models.load_model(self.info[\"encoderFile\"])\n",
        "        self.decoder = tf.keras.models.load_model(self.info[\"decoderFile\"])\n",
        "        self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "        self.encoder.compile(optimizer=optimizer, loss=loss)\n",
        "        self.decoder.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    # Save model architecture and weights to file\n",
        "    def save_models(self):\n",
        "        print(\"Saving models...\")\n",
        "        self.autoencoder.save(self.info[\"autoencoderFile\"])\n",
        "        self.encoder.save(self.info[\"encoderFile\"])\n",
        "        self.decoder.save(self.info[\"decoderFile\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZu7MtnK3_9P",
        "outputId": "05e25c5b-af9a-4aa9-f391-a967923fea45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Run mode: (autoencoder -> simpleAE, convAE) or (transfer learning -> vgg19)\n",
        "modelName = \"convAE\"  # try: \"simpleAE\", \"convAE\", \"vgg19\"\n",
        "trainModel = True\n",
        "parallel = True  # use multicore processing\n",
        "\n",
        "# Make paths\n",
        "dataTrainDir = '/content/gdrive/My Drive/aetrain/'\n",
        "dataTestDir = '/content/gdrive/My Drive/aetest/'\n",
        "outDir = '/content/gdrive/My Drive/output/convAE'\n",
        "# if not os.path.exists(outDir):\n",
        "#     os.makedirs(outDir)\n",
        "\n",
        "# Read images\n",
        "extensions = [\".jpg\", \".jpeg\"]\n",
        "print(\"Reading train images from '{}'...\".format(dataTrainDir))\n",
        "imgs_train = read_imgs_dir(dataTrainDir, extensions, parallel=parallel)\n",
        "print(\"Reading test images from '{}'...\".format(dataTestDir))\n",
        "imgs_test = read_imgs_dir(dataTestDir, extensions, parallel=parallel)\n",
        "shape_img = imgs_train[0].shape\n",
        "print(\"Image shape = {}\".format(shape_img))\n",
        "\n",
        "# Build models\n",
        "if modelName in [\"simpleAE\", \"convAE\"]:\n",
        "\n",
        "    # Set up autoencoder\n",
        "    info = {\n",
        "        \"shape_img\": shape_img,\n",
        "        \"autoencoderFile\": os.path.join(outDir, \"{}_autoecoder.h5\".format(modelName)),\n",
        "        \"encoderFile\": os.path.join(outDir, \"{}_encoder.h5\".format(modelName)),\n",
        "        \"decoderFile\": os.path.join(outDir, \"{}_decoder.h5\".format(modelName)),\n",
        "    }\n",
        "    model = AutoEncoder(modelName, info)\n",
        "    model.set_arch()\n",
        "\n",
        "    if modelName == \"simpleAE\":\n",
        "        shape_img_resize = shape_img\n",
        "        input_shape_model = (model.encoder.input.shape[1],)\n",
        "        output_shape_model = (model.encoder.output.shape[1],)\n",
        "        n_epochs = 300\n",
        "    elif modelName == \"convAE\":\n",
        "        shape_img_resize = shape_img\n",
        "        input_shape_model = tuple([int(x) for x in model.encoder.input.shape[1:]])\n",
        "        output_shape_model = tuple([int(x) for x in model.encoder.output.shape[1:]])\n",
        "        n_epochs = 500\n",
        "    else:\n",
        "        raise Exception(\"Invalid modelName!\")\n",
        "\n",
        "elif modelName in [\"vgg19\"]:\n",
        "\n",
        "    # Load pre-trained VGG19 model + higher level layers\n",
        "    print(\"Loading VGG19 pre-trained model...\")\n",
        "    model = tf.keras.applications.VGG19(weights='imagenet', include_top=False,\n",
        "                                        input_shape=shape_img)\n",
        "    model.summary()\n",
        "\n",
        "    shape_img_resize = tuple([int(x) for x in model.input.shape[1:]])\n",
        "    input_shape_model = tuple([int(x) for x in model.input.shape[1:]])\n",
        "    output_shape_model = tuple([int(x) for x in model.output.shape[1:]])\n",
        "    n_epochs = None\n",
        "\n",
        "else:\n",
        "    raise Exception(\"Invalid modelName!\")\n",
        "\n",
        "# Print some model info\n",
        "print(\"input_shape_model = {}\".format(input_shape_model))\n",
        "print(\"output_shape_model = {}\".format(output_shape_model))\n",
        "\n",
        "# Apply transformations to all images\n",
        "class ImageTransformer(object):\n",
        "\n",
        "    def __init__(self, shape_resize):\n",
        "        self.shape_resize = shape_resize\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_transformed = resize_img(img, self.shape_resize)\n",
        "        img_transformed = normalize_img(img_transformed)\n",
        "        return img_transformed\n",
        "\n",
        "transformer = ImageTransformer(shape_img_resize)\n",
        "print(\"Applying image transformer to training images...\")\n",
        "imgs_train_transformed = apply_transformer(imgs_train, transformer, parallel=parallel)\n",
        "print(\"Applying image transformer to test images...\")\n",
        "imgs_test_transformed = apply_transformer(imgs_test, transformer, parallel=parallel)\n",
        "\n",
        "# Convert images to numpy array\n",
        "X_train = np.array(imgs_train_transformed).reshape((-1,) + input_shape_model)\n",
        "X_test = np.array(imgs_test_transformed).reshape((-1,) + input_shape_model)\n",
        "print(\" -> X_train.shape = {}\".format(X_train.shape))\n",
        "print(\" -> X_test.shape = {}\".format(X_test.shape))\n",
        "\n",
        "# Train (if necessary)\n",
        "if modelName in [\"simpleAE\", \"convAE\"]:\n",
        "    if trainModel:\n",
        "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "        model.fit(X_train, n_epochs=n_epochs, batch_size=256)\n",
        "        model.save_models()\n",
        "    else:\n",
        "        model.load_models(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Create embeddings using model\n",
        "print(\"Inferencing embeddings using pre-trained model...\")\n",
        "E_train = model.predict(X_train)\n",
        "E_train_flatten = E_train.reshape((-1, np.prod(output_shape_model)))\n",
        "E_test = model.predict(X_test)\n",
        "E_test_flatten = E_test.reshape((-1, np.prod(output_shape_model)))\n",
        "print(\" -> E_train.shape = {}\".format(E_train.shape))\n",
        "print(\" -> E_test.shape = {}\".format(E_test.shape))\n",
        "print(\" -> E_train_flatten.shape = {}\".format(E_train_flatten.shape))\n",
        "print(\" -> E_test_flatten.shape = {}\".format(E_test_flatten.shape))\n",
        "\n",
        "# Make reconstruction visualizations\n",
        "if modelName in [\"simpleAE\", \"convAE\"]:\n",
        "    print(\"Visualizing database image reconstructions...\")\n",
        "    imgs_train_reconstruct = model.decoder.predict(E_train)\n",
        "    if modelName == \"simpleAE\":\n",
        "        imgs_train_reconstruct = imgs_train_reconstruct.reshape((-1,) + shape_img_resize)\n",
        "    plot_reconstructions(imgs_train, imgs_train_reconstruct,\n",
        "                         os.path.join(outDir, \"{}_reconstruct.png\".format(modelName)),\n",
        "                         range_imgs=[0, 255],\n",
        "                         range_imgs_reconstruct=[0, 1])\n",
        "\n",
        "# Fit kNN model on training images\n",
        "print(\"Fitting k-nearest-neighbour model on training images...\")\n",
        "knn = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n",
        "knn.fit(E_train_flatten)\n",
        "\n",
        "# Perform image retrieval on test images\n",
        "print(\"Performing image retrieval on test images...\")\n",
        "for i, emb_flatten in enumerate(E_test_flatten):\n",
        "    _, indices = knn.kneighbors([emb_flatten]) # find k nearest train neighbours\n",
        "    img_query = imgs_test[i] # query image\n",
        "    imgs_retrieval = [imgs_train[idx] for idx in indices.flatten()] # retrieval images\n",
        "    outFile = os.path.join(outDir, \"{}_retrieval_{}.png\".format(modelName, i))\n",
        "    plot_query_retrieval(img_query, imgs_retrieval, outFile)\n",
        "\n",
        "# Plot t-SNE visualization\n",
        "print(\"Visualizing t-SNE on training images...\")\n",
        "outFile = os.path.join(outDir, \"{}_tsne.png\".format(modelName))\n",
        "plot_tsne(E_train_flatten, imgs_train, outFile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train images from '/content/gdrive/My Drive/aetrain/'...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}